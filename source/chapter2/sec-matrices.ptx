<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-matrices" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Matrices</title>
    <p>
        We already discussed matrices briefly when we studied the Gauss--Jordan elimination algorithm. In that setting, the main purpose of assigning a matrix to a linear system was to simplify notation and clarify the operations required to transform the given system into one in reduced row echelon form. However, matrices play a much more important role in linear algebra. As we will soon see, an <m>m\times n</m> matrix encodes the information required to describe a particular kind of function from <m>\R^n</m> to <m>\R^m</m>: a <em>linear map</em>. But before we speak about linear maps, we need to discuss matrix addition and multiplication.
    </p>
    <p>
        If the number of rows of a matrix <m>A</m> is the same as the number of rows of a matrix <m>B</m>, and if the same is true of the number of columns, then it is possible to define the sum <m>A+B</m> of <m>A</m> and <m>B</m>. This sum will also be a matrix with the same number of rows of <m>A</m> (and of <m>B</m>) and the same number of columns of <m>A</m> (and of <m>B</m>). Let's see the formal description of matrix addition.
    </p>
    <definition xml:id="def-matrix-addition">
        <title>Matrix addition</title>
        <statement>
            <p>
                Let <m>m</m> and <m>n</m> be two positive integers, and let <m>A=(a_{ij})_{ij}</m> and <m>B=(b_{ij})_{ij}</m> be two <m>m\times n</m> matrices. Recall that this short-hand notation means that the entry in row <m>i</m> and column <m>j</m> of matrix <m>A</m> is <m>a_{ij}</m>, and the entry in row <m>i</m> and column <m>j</m> of matrix <m>B</m> is <m>b_{ij}</m>. The matrix <m>A+B</m> is the <m>m\times n</m> matrix whose <m>(i,j)</m> entry is given by <m>a_{ij}+b_{ij}</m>. Visually,
                <me>
                    \left(
                    \begin{array}{cccc}
                        a_{11} \amp a_{12} \amp \cdots \amp a_{1n}\\
                        a_{21} \amp a_{22} \amp \cdots \amp a_{2n}\\
                        \vdots \amp \vdots \amp \ddots \amp \vdots \\
                        a_{m1} \amp a_{m2} \amp \cdots \amp a_{mn}
                    \end{array}\right) +
                    \left(
                    \begin{array}{cccc}
                        b_{11} \amp b_{12} \amp \cdots \amp b_{1n}\\
                        b_{21} \amp b_{22} \amp \cdots \amp b_{2n}\\
                        \vdots \amp \vdots \amp \ddots \amp \vdots \\
                        b_{m1} \amp b_{m2} \amp \cdots \amp b_{mn}
                    \end{array}\right) =
                    \left(
                    \begin{array}{cccc}
                        a_{11} + b_{11} \amp a_{12} + b_{12} \amp \cdots \amp a_{1n} + b_{1n}\\
                        a_{21} + b_{21} \amp a_{22} + b_{22} \amp \cdots \amp a_{2n}+ b_{2n}\\
                        \vdots \amp \vdots \amp \ddots \amp \vdots \\
                        a_{m1} + b_{m1}\amp a_{m2}+b_{m2} \amp \cdots \amp a_{mn} + b_{mn}
                    \end{array}\right)
                </me>.
            </p>
        </statement>
    </definition>
    <example>
        <p>
            If <m>A=\left(\begin{array}{ccc} 1 \amp -2 \amp 0 \\ 3 \amp 7 \amp -5\end{array}\right)</m> and <m>B=\left(\begin{array}{ccc} 3 \amp 0 \amp -4 \\ -\sqrt{2} \amp 3 \amp 1\end{array}\right)</m>, then
            <me>
                A+B=\left(\begin{array}{ccc} 4 \amp -2 \amp -4 \\ 3-\sqrt{2} \amp 10 \amp -4\end{array}\right)
            </me>.
        </p>
    </example>
    <example>
        <p>
            Vectors of <m>\R^n</m> are a special kind of matrix. Indeed, they can be regarded as <m>n\times 1</m> matrices, i.e. matrices with <m>n</m> rows and a single column. Under this interpretation, matrix addition and vector addition are compatible.
        </p>
    </example>
    <p>
        We will denote the set of <m>m\times n</m> matrices by <m>\Mat_{m\times n}</m>. So, <m>A\in\Mat_{m\times n}</m> means that <m>A</m> is an <m>m\times n</m> matrix.
    </p>
    <p>
        If <m>A=(a_{ij})_{ij}</m> is an <m>m\times n</m> matrix, then we define <m>-A</m> to be the matrix <m>(-a_{ij})_{ij}</m>. It is easy to check (you should do it!) that <m>A+(-A)=0</m>, the zero matrix.
    </p>
    <p>
        It is also possible to multiply matrices by a scalar.
    </p>
    <definition xml:id="def-matrix-scalar-multiplication">
        <statement>
            <p>
                If <m>\lambda\in \R</m> is a scalar and <m>A=(a_{ij})_{ij}</m> is an <m>m\times n</m> matrix, the matrix <m>\lambda A</m> is defined to be the matrix <m>(\lambda a_{ij})_{ij}</m>. In other words, it is the <m>m\times n</m> matrix obtained from <m>A</m> by multiplying each entry by <m>\lambda</m>.
            </p>
        </statement>
    </definition>
    <example>
        <p>
            If <m>A=\begin{pmatrix} 1 \amp 3 \amp -1 \\ -2 \amp 0 \amp 4\end{pmatrix}</m>, then
            <me>
                3A=\begin{pmatrix} 3 \amp 9 \amp -3 \\ -6 \amp 0 \amp 12 \end{pmatrix}
            </me>.
        </p>
    </example>
    <exercise>
        <p>
            Show that <m>(-1)\cdot A=-A</m> for any matrix <m>A</m>.
        </p>
    </exercise>
    <p>
        The properties of matrix addition listed in the following lemma follow almost immediately from the corresponding properties of real number addition, and you should prove them yourself.
    </p>
    <lemma xml:id="lem-matrix-addition-props">
        <statement>
            <p>
                Let <m>m</m> and <m>n</m> be positive real numbers. Let <m>A,B</m> and <m>C</m> be <m>m\times n</m> matrices and <m>\lambda,\mu\in\R</m> scalars. The following properties hold:
                <ol>
                    <li>
                        <p>
                            <m>A+B=B+A</m>.
                        </p>
                    </li>
                    <li>
                        <p>
                            <m>(A+B)+C=A+(B+C)</m>.
                        </p>
                    </li>
                    <li>
                        <p>
                            <m>\lambda(A+B)=\lambda A+\lambda B</m>.
                        </p>
                    </li>
                    <li>
                        <p>
                            <m>(\lambda+\mu)A=\lambda A + \mu A</m>.
                        </p>
                    </li>
                </ol>
            </p>
        </statement>
    </lemma>
    <p>
        Another important operation that one can perform on matrices is that of <em>transposition</em>.
    </p>
    <definition xml:id="def-matrix-transposition">
        <title>Transpose</title>
        
        
        <statement>
            <p>
                If <m>A=(a_{ij})_{ij}</m> is an <m>m\times n</m> matrix, then the <em>transpose</em> of <m>A</m>, denoted <m>A^T</m>, is the <m>n\times m</m> matrix <m>A^T:=(a_{ji})_{ij}</m>. In other words, the <m>(i,j)</m> entry of <m>A^T</m> is defined to be the <m>(j,i)</m> entry of <m>A</m>.
            </p>
        </statement>
    </definition>
    <example>
        <p>
            If <m>A=\begin{pmatrix} 1 \amp 2 \amp 3 \\ 4 \amp 5 \amp 6\end{pmatrix}</m>, then the transpose of <m>A</m> is
            <me>
                A^T=\begin{pmatrix} 1 \amp 4 \\ 2 \amp 5 \\ 3 \amp 6 \end{pmatrix}
            </me>.
        </p>
    </example>
    <example>
        <p>
            If <m>A=\begin{pmatrix} 1 \amp 2 \\ 3 \amp 4\end{pmatrix}</m>, then the transpose of <m>A</m> is
            <me>
                A^T=\begin{pmatrix} 1 \amp 3 \\ 2 \amp 4\end{pmatrix}
            </me>.
        </p>
    </example>
    <example xml:id="example-transpose-vector">
        <p>
            Regard the vector <m>\bv=\colvec{1 \\ 2 \\ 3}</m> as a <m>3\times 1</m> matrix. Then we can consider its transpose
            <me>
                \bv^T=\begin{pmatrix} 1 \amp 2 \amp 3\end{pmatrix}
            </me>.
        </p>
    </example>
    <p>
        I want to point out an important subtlety related to Example <xref ref="example-transpose-vector"/>. As you know, a vector in <m>\R^n</m> is simply an ordered collection of <m>n</m> real numbers. A single vector may be represented in many different ways. For reasons that are going to become apparent before the end of this section, we chose to represent vectors vertically. However, this is simply a choice and the vector <m>\colvec{1 \\ 2}</m> for example, <em>as a vector</em>, is the same as the vector <m>(1,2)</m> or <m>\begin{pmatrix} 1 \amp 2\end{pmatrix}</m>. (In the same way that the number <em>five</em> may be represented by the Arabic numeral <m>5</m> or by the Roman numeral V.) But while <m>\begin{pmatrix} 1 \amp 2\end{pmatrix}</m> and <m>\colvec{1 \\ 2}</m> represent the same vector, they <em>do not</em> represent the same matrix. Matrices have a certain number of rows and a certain number of columns, and both these numbers and the entries are important.
    </p>
    <p>
        This being said, you may sometimes encounter the expressions <em>row vector</em> and <em>column vector</em>. These expressions actually refer to two types of <em>matrices</em>. A <em>row vector</em> is a <m>1\times n</m> matrix, while a <em>columns vector</em> is an <m>n\times 1</m> matrix. As mentioned before, we will choose to represent vectors using column vectors.
    </p>
    <example>
        <p>
            If instead of starting with a column vector as in Example <xref ref="example-transpose-vector"/> we start with a row vector like <m>\bw=\begin{pmatrix}1 \amp 2 \amp 3\end{pmatrix}</m>, then the transpose of <m>\bw</m> is the column vector
            <me>
                \bw^T=\colvec{1 \\ 2 \\ 3}
            </me>.
        </p>
    </example>
    <p>
        Since the transpose of a matrix is a matrix again, one is able to transpose the transpose! You should have no trouble checking that <m>(A^T)^T=A</m>. In other words, the transpose of a transpose is initial matrix.
    </p>
    <exercise>
        <p>
            Show that if <m>A</m> is a matrix, then <m>(A^T)^T=A</m>.
        </p>
    </exercise>
    <p>
        We finally come to the question of matrix multiplication. Matrix multiplication is a curious operation. Some natural properties of real number multiplication simply do not hold in general in the case of matrices. Perhaps the most shocking property not satisfied by matrix multiplication is commutativity. We will soon see that it is not necessarily true that <m>AB=BA</m>. In fact, it may happen that only the product <m>AB</m> is defined and that it is not possible to multiply <m>B</m> by <m>A</m> at all!
    </p>
    <definition xml:id="def-matrix-multiplication">
        <title>Matrix multiplication</title>
        
        
        <statement>
            <p>
                Let <m>m,n</m> and <m>r</m> be positive integers. If <m>A=(a_{ij})_{ij}</m> is an <m>m\times n</m> matrix and <m>B=(b_{ij})_{ij}</m> is an <m>n\times r</m> matrix, then the product <m>AB</m> is the <m>m\times r</m> matrix whose <m>(i,j)</m> entry <m>c_{ij}</m> is defined to be 
                <me>
                    c_{ij}=\sum_{k=1}^n a_{ik}b_{kj}=a_{i1}b_{1j}+a_{i2}b_{2j}+\ldots+a_{in}b_{nj}
                </me>.
            </p>
        </statement>
    </definition>
    <p>
        The definition may not be very transparent when you first read it. Here is a better way of describing <m>AB</m>. In order to calculate the entry in the <m>i</m>th row and <m>j</m>th column of <m>AB</m>, start by considering the vector <m>\br_i</m> formed by the <m>i</m>th row of the matrix <m>A</m>, and also consider the column vector <m>\bc_j</m> formed by the <m>j</m>th column of <m>B</m>. The entry in the <m>i</m>th row and <m>j</m>th column of <m>AB</m> is then the dot product <m>\br_i\cdot\bc_j</m>.
    </p>
    <example xml:id="example-matrix-multiplication-first">
        <p>
            Consider the matrices <m>A=\begin{pmatrix}1 \amp 3 \amp 4 \\ 2 \amp -1 \amp -2 \end{pmatrix}</m> and <m>B=\begin{pmatrix}-1 \amp 0 \amp 1 \\ 2 \amp 1 \amp 0 \\ 3\amp -2 \amp 1\end{pmatrix}</m>. Since <m>A</m> has <m>3</m> columns and <m>B</m> has <m>3</m> rows, the product <m>AB</m> is defined. However, we cannot take the product <m>BA</m> because the number of columns of <m>B</m> is <m>3</m>, while the number of rows of <m>A</m> is <m>2</m>.
        </p>
        <p>
            Let's calculate <m>AB</m>. For starters, we know that the product <m>AB</m> is going to be a <m>2\times 3</m> matrix: the number of rows matches the number of rows of <m>A</m>, while the number of columns is the number of columns of <m>B</m>. Let's denote by <m>c_{ij}</m> the <m>(i,j)</m> entry of <m>AB</m>. Then <m>c_{11}</m> is the dot product of the vector formed by the first row of <m>A</m> and the one formed by the first column of <m>B</m>:
            <me>
                c_{11}=\colvec{1 \\ 3 \\ 4}\cdot \colvec{-1 \\ 2 \\ 3}=-1+6+12=17
            </me>.
            The entry <m>c_{12}</m> is the dot product of the first row of <m>A</m> and the second column of <m>B</m>:
            <me>
                c_{12}=\colvec{1 \\ 3 \\ 4}\cdot \colvec{0 \\ 1 \\ -2}=3-8=-5
            </me>.
            Similarly, to compute <m>c_{13}</m> one must take the dot product between the vector formed by the first row of <m>A</m> and the third column of <m>B</m>:
            <me>
                c_{13}=\colvec{1 \\ 3 \\ 4} \cdot \colvec{1 \\ 0 \\ 1}=1 + 4=5
            </me>.
            We then proceed in a similar manner with the second row of <m>A</m>. We eventually find 
            <me>
                AB=\begin{pmatrix}17 \amp -5 \amp 5 \\ -10 \amp 3 \amp 0\end{pmatrix}
            </me>.
        </p>
    </example>
    <p>
        <xref ref="example-matrix-multiplication-first"/> provides a first glimpse of the phenomenon I alluded to a few paragraphs ago. Here we have a pair of matrices <m>A</m> and <m>B</m> for which the product <m>AB</m> is defined and the product <m>BA</m> is not. The issue here is that the product of two matrices is only defined if the number of columns of the first matrix equals the number of columns of the second.
    </p>
    <p>
        If matrix <m>A</m> is an <m>m\times n</m> matrix and <m>B</m> is an <m>n\times m</m> matrix, then both <m>AB</m> and <m>BA</m> are defined. Yet, even in this situation, we will often have <m>AB\neq BA</m>.
    </p>
    <example>
        <p>
            Let <m>A=\begin{pmatrix}1 \amp 2 \\ 3 \amp 4\end{pmatrix}</m> and <m>B=\begin{pmatrix} -1 \amp 1 \\ 3 \amp 0\end{pmatrix}</m>. Then
            <me>
                AB=\begin{pmatrix}5 \amp 1 \\ 9 \amp 3\end{pmatrix}
            </me>,
            but
            <me>
                BA=\begin{pmatrix}2 \amp 2 \\ 3 \amp 6\end{pmatrix}
            </me>.
        </p>
    </example>
    <p>
        Despite the failure of commutativity in general, there are a few familiar properties that matrix multiplication satisfies. Again, I encourage you to prove the following properties using the definition of matrix multiplication.
    </p>
    <lemma xml:id="lem-matrix-multiplication-props">
        <statement>
            <p>
                Let <m>m,n,r</m> and <m>s</m> be positive integers. Let <m>A</m> be an <m>m\times n</m> matrix, <m>B</m> and <m>C</m> two <m>n\times r</m> matrices, and <m>D</m> an <m>r\times s</m> matrix. Let <m>\lambda\in \R</m> be a scalar. The following properties hold.
                <ol>
                    <li>
                        <p>
                            <m>A(B+C)=AB+AC</m> and <m>(B+C)D=BD+CD</m>.
                        </p>
                    </li>
                    <li>
                        <p>
                            <m>A(BD)=(AB)D</m>.
                        </p>
                    </li>
                    <li>
                        <p>
                            <m>\lambda(AB)=(\lambda A)B=A(\lambda B)</m>.
                        </p>
                    </li>
                    <li>
                        <p>
                            <m>(AB)^T=B^TA^T</m>.
                        </p>
                    </li>
                </ol>
            </p>
        </statement>
        <proof>
            <p>
                As an example, I will prove property number <m>4</m>.
            </p>
            <p>
                Say that the <m>(i,j)</m> entry of <m>A</m> is <m>a_{ij}</m>, that of <m>B</m> is <m>b_{ij}</m>, that of <m>AB</m> is <m>c_{ij}</m>, and that of <m>B^TA^T</m> is <m>d_{ij}</m>. By the definition of matrix multiplication, we have
                <me>
                    c_{ij}=\sum_{k=1}^n a_{ik}b_{kj}
                </me>.
                Therefore, the <m>(i,j)</m> entry of <m>(AB)^T</m> is 
                <me>
                    c_{ji} = \sum_{k=1}^n a_{jk}b_{ki}
                </me>.
                Let's now calculate the <m>(i,j)</m> entry of <m>B^T A^T</m> and check that it matches the expression for <m>c_{ji}</m>. The <m>(i,j)</m> entry of <m>A^T</m> is <m>a_{ji}</m> and that of <m>B^T</m> is <m>b_{ji}</m>. It follows that the <m>(i,j)</m> entry of <m>B^TA^T</m>, which we chose to call <m>d_{ij}</m> is given by the expression
                <me>
                    d_{ij}=\sum_{k=1}^n b_{ki}a_{jk}=\sum_{k=1}^n a_{jk}b_{ki}=c_{ji}
                </me>,
                as we wanted.
            </p>
            <p>
                If you wanted, you could use the interpretation of matrix multiplication as a collection of dot products of the vectors formed by the rows of the first matrix and columns of the second to give an alternative proof of property <m>4</m>. Indeed, denote by <m>\br_i</m> the <m>i</m>th row of <m>A</m> and by <m>\bc_j</m> the <m>j</m>th column of <m>B</m>. Then, for any <m>1\leq i\leq m</m> and <m>1\leq j\leq r</m>, the <m>(i,j)</m> entry of <m>AB</m> is the dot product <m>\br_i\cdot \bc_j</m>. This means that for <m>1\leq i\leq r</m> and <m>1\leq j\leq m</m> the <m>(i,j)</m> entry of <m>(AB)^T</m> is <m>\br_j\cdot \bc_i</m>.
            </p>
            <p>
                Now note that the vector defined by the <m>j</m>th column of <m>A^T</m> is precisely <m>\br_j</m>, while the vector defined by the <m>i</m>th row of <m>B^T</m> is <m>\bc_i</m>. Therefore, the <m>(i,j)</m> entry of <m>B^TA^T</m> is the dot product <m>\bc_i\cdot \br_j</m>. By the commutativity of the dot product, we conclude that this is the same as <m>\br_j\cdot \bc_i</m>.
            </p>
        </proof>
    </lemma>
    <p>
        It should be pointed out that property <m>3</m> in <xref ref="lem-matrix-multiplication-props"/> is a special case of property <m>2</m>. Indeed, multiplying an <m>m\times n</m> matrix <m>A</m> by a scalar <m>\lambda\in\R</m> has the same effect as multiplying the <m>m\times m</m> matrix
        <me>
            \begin{pmatrix} \lambda \amp 0 \amp \cdots \amp 0\\ 0 \amp \lambda \amp \cdots \amp 0 \\ \vdots \amp \vdots \amp \ddots \amp \vdots \\ 0 \amp 0 \amp \cdots \amp \lambda\end{pmatrix}
        </me>
        by <m>A</m>. The matrix above is an example of a member of a family of square matrices called <em>scalar matrices</em>.
    </p>
    <definition xml:id="def-square-diagonal">
        <statement>
            <p>
                An <m>m\times n</m> matrix is called a <term>square matrix</term> if <m>m=n</m>, i.e. if it has as many rows as it has columns.
            </p>
            <p>
                A square matrix <m>A=(a_{ij})_{1\leq i\leq n,1\leq j\leq n}</m> is called a <term>diagonal matrix</term> if <m>a_{ij}=0</m> whenever <m>i\neq j</m>. In other words, if the only non-zero entries occur along the main diagonal.
            </p>
            <p>
                A <term>scalar matrix</term> is a diagonal matrix whose entries in the main diagonal are all equal.
            </p>
        </statement>
    </definition>
    <p>
        If <m>\lambda_1,\lambda_2,\ldots,\lambda_n</m> are <m>n</m> real numbers, then the <m>n\times n</m> diagonal matrix with entries <m>\lambda_1,\lambda_2,\ldots,\lambda_n</m> is often denoted by <m>\diag(\lambda_1,\lambda_2,\ldots,\lambda_n)</m>:
        <me>
            \diag(\lambda_1,\lambda_2,\ldots,\lambda_n)=\begin{pmatrix}\lambda_1 \amp 0 \amp \cdots \amp 0\\ 0 \amp \lambda_2 \amp \cdots \amp 0\\ \vdots \amp \vdots \amp \ddots \amp \vdots \\ 0 \amp 0 \amp \cdots \amp \lambda_n\end{pmatrix}
        </me>.
    </p>
    <example>
        <p>
            For example,
            <me>
                \diag(1,0,3)=\begin{pmatrix} 1 \amp 0 \amp 0 \\ 0 \amp 0 \amp 0 \\ 0 \amp 0 \amp 3\end{pmatrix}
            </me>
            and 
            <me>
                \diag(5,5)=\begin{pmatrix} 5 \amp 0 \\ 0 \amp 5\end{pmatrix}
            </me>.
        </p>
    </example>
    <p>
        Using this notation, a scalar matrix is a diagonal matrix of the form <m>\diag(\lambda,\lambda,\ldots,\lambda)</m> for some <m>\lambda\in \R</m>. Equivalently, a scalar matrix is a matrix of the form <m>\lambda\Id_n</m>, where, recall, <m>\Id_n</m> is the <m>n\times n</m> identity matrix:
        <me>
            \Id_n=\begin{pmatrix} 1 \amp 0 \amp \cdots \amp 0 \\ 0 \amp 1 \amp \cdots \amp 0 \\ \vdots \amp \vdots \amp \ddots \amp \vdots \\ 0 \amp 0 \amp \cdots \amp 1\end{pmatrix}
        </me>.
    </p>
    <p>
        Note that multiplication by a scalar matrix boils down to multiplication by the scalar in the main diagonal, i.e. if <m>\diag(\lambda,\lambda,\ldots,\lambda)</m> is the <m>m\times m</m> scalar matrix with <m>\lambda</m> in the main diagonal, and if <m>A</m> is an <m>m\times n</m> matrix, then
        <me>
            \diag(\lambda,\lambda,\ldots,\lambda)A=\lambda A
        </me>.
        This means that scalar matrices behave very much like scalars. Using this fact, one can easily deduce property 3 in <xref ref="lem-matrix-multiplication-props"/> from property 2.
    </p>
    <p>
        If we identify scalars with scalar matrices, we are now able to make sense of <m>p(A)</m> for any polynomial <m>p(X)\in\R[X]</m> and square matrix <m>A</m>.
    </p>
    <example>
        <p>
            Consider the polynomial <m>p(X)=X^2-2X+5</m> and the matrix <m>A=\begin{pmatrix} 1 \amp -1 \\ 0 \amp 2\end{pmatrix}</m>. Then
            <md>
                <mrow>p(A)=A^2-2A+5\Id_2 \amp =\begin{pmatrix} 1 \amp -3 \\ 0 \amp 4\end{pmatrix} -2\begin{pmatrix} 1 \amp -1 \\ 0 \amp 2\end{pmatrix} +\begin{pmatrix} 5 \amp 0 \\ 0 \amp 5 \end{pmatrix}</mrow>
                <mrow> \amp=\begin{pmatrix} 4 \amp -1 \\ 0 \amp 5\end{pmatrix} </mrow>
            </md>.
        </p>
    </example>
    <p>
        You may be wondering why matrix multiplication is defined in this convoluted way. After all, adding two matrices is nothing more than adding the corresponding entries. Why isn't matrix multiplication defined that way too?
    </p>
    <p>
        As I pointed out at the start of this section, an <m>m\times n</m> matrix represents a very special type of function from <m>\R^n</m> to <m>\R^m</m> called a <term>linear map</term>. If we have an <m>m\times n</m> matrix <m>A</m> and an <m>n\times r</m> matrix <m>B</m>, then we have two linear maps: on function <m>\phi_A</m> from <m>\R^n</m> to <m>\R^m</m>, and another one, <m>\phi_B</m>, from <m>\R^r</m>to <m>\R^n</m>. We can therefore form the composition <m>\phi_A\circ\phi_B</m>, which turns out to be a linear map. We can then wonder what is the matrix that describes this composition. This matrix is precisely the product <m>AB</m>. Simply put, the matrix product was defined to ensure that matrix multiplication corresponds to composition of linear maps.
    </p>
    <p>
        Note that from this perspective it is not surprising that, in general, matrix multiplication is not commutative. Indeed, it is rarely the case that composition of functions commutes!
    </p>
    <p>
        This is all well and good, but I have yet to tell you how matrices define functions at all. This is our next goal.
    </p>
    <p>
        The description of the function defined by a matrix is actually very simple. Consider an <m>m\times n</m> matrix <m>A</m>, and let <m>\bv</m> be a vector in <m>\R^n</m>. If we view <m>\bv</m> as a column vector (i.e., as a <m>n\times 1</m> matrix), we can multiply <m>A</m> and <m>\bv</m> together to get a <m>m\times 1</m> matrix <m>A\bv</m> (i.e., another column vector). Thus, <m>A\bv</m> represents a vector in <m>\R^m</m>. We define the function <m>\varphi_A:\R^n\rightarrow \R^m</m> by setting <m>\varphi_A(\bv)=A\bv</m>.
    </p>
    <example>
        <p>
            Consider the matrix <m>A=\begin{pmatrix}\frac{\sqrt{2}}{2} \amp -\frac{\sqrt{2}}{2}\\ \frac{\sqrt{2}}{2} \amp \frac{\sqrt{2}}{2}\end{pmatrix}</m>. Being a <m>2\times 2</m> matrix, it defines a function <m>\varphi_A:\R^2\rightarrow \R^2</m>. We can describe this function explicitly as follows. Let <m>\bv=\colvec{x \\ y}</m> be a vector in <m>\R^2</m>. By definition, we have
            <me>
                \varphi_A(\bv)=\begin{pmatrix}\frac{\sqrt{2}}{2} \amp -\frac{\sqrt{2}}{2}\\ \frac{\sqrt{2}}{2} \amp \frac{\sqrt{2}}{2}\end{pmatrix}\colvec{x \\ y}=\colvec{\frac{\sqrt{2}}{2}x - \frac{\sqrt{2}}{2}y \\ \frac{\sqrt{2}}{2}x + \frac{\sqrt{2}}{2}y}
            </me>.
            So, <m>\varphi_A(x,y)=\left(\frac{\sqrt{2}}{2}x - \frac{\sqrt{2}}{2}y, \frac{\sqrt{2}}{2}x + \frac{\sqrt{2}}{2}y\right)</m>.
        </p>
        <p>
            It is instructive to see what happens to the standard unit vectors <m>\be_1=\colvec{1 \\ 0}</m> and <m>\be_2=\colvec{0 \\ 1}</m> of <m>\R^2</m> when we hit them with this map. One can easily calculate that
            <me>
                A\be_1=\colvec{\frac{\sqrt{2}}{2} \\ \frac{\sqrt{2}}{2}}\qquad\text{and}\qquad A\be_2=\colvec{-\frac{\sqrt{2}}{2} \\ \frac{\sqrt{2}}{2}}
            </me>.
                The figure below shows <m>\varphi_A(\be_1)</m> in blue and <m>\varphi_A(e_2)</m> in orange.
        </p>
        <figure xml:id="fig-rotation">
            <caption>The effect of <m>\varphi_A</m> on the standard unit vectors.</caption>
                <image width="80%">
                    <shortdescription>The vectors obtained by rotating the standard unit vectors of r2 by pi over four radians.</shortdescription>
                    <prefigure xmlns="https://prefigure.org" label="prefig-rotation">
                        <diagram dimensions="(300,300)" margins="5">
                            <definition>v=(sqrt(2)/2,sqrt(2)/2)</definition>
                            <definition>w=(-sqrt(2)/2,sqrt(2)/2)</definition>
                            <coordinates bbox="(-1.5,-1.5, 1.5, 1.5)">
                                <grid-axes xlabel="x" ylabel="y" />
                                <vector v="v" stroke="blue" thickness="2" />
                                <vector v="w" stroke="orange" thickness="2" />
                            </coordinates>
                        </diagram>
                    </prefigure>                    
                </image>
        </figure>
        <p>
            What we see in the image above is that the vectors <m>\be_1</m> and <m>\be_2</m> were both rotated <m>\pi/4</m> radians counterclockwise. In fact, the action of <m>\varphi_A</m> on every vector of <m>\R^2</m> is precisely rotation by <m>\pi/4</m> radians.
        </p>
    </example>
    <example>
        <p>
            The function <m>f(\bv)=2\bv</m> (i.e. the function that scales every vector by a factor of <m>2</m>) is the same as <m>\varphi_A</m> for the matrix
            <m>
                A=\begin{pmatrix} 2 \amp 0 \\ 0 \amp 2\end{pmatrix}
            </m>.
        </p>
    </example>
    <p>
        Explicitly, the function <m>\varphi_A:\R^n\rightarrow \R^m</m> defined by the matrix 
        <me>
            A=\begin{pmatrix} a_{11} \amp a_{12} \amp \ldots \amp a_{1n} \\ a_{21} \amp a_{22} \amp \ldots \amp a_{2n}\\ \vdots \amp \vdots \amp \ddots \amp \vdots \\ a_{m1} \amp a_{m2} \amp \ldots \amp a_{mn}\end{pmatrix}
        </me>
        is the function that maps the vector <m>\bv=\colvec{x_1 \\ x_2 \\ \vdots \\ x_n}</m> to the vector
        <me>
            A\bv=\colvec{a_{11}x_1 + a_{12}x_2 +\ldots+a_{1n}x_n \\ a_{21}x_1+a_{22}x_2 +\ldots+a_{2n}x_n\\ \vdots\\ a_{m1}x_1+a_{m2}x_2+\ldots + a_{mn}x_n}
        </me>.
    </p>
    <p>
        Imagine now that I give you a vector <m>\bb=\colvec{b_1 \\ b_2 \\ \vdots \\ b_n}</m> in <m>\R^n</m> and I ask you whether <m>\bb</m> is in the image of <m>\varphi_A</m>. How would you go about deciding this?
    </p>
    <p>
        The question that I am asking is whether there is a vector <m>\bv\in\R^n</m> such that
        <me>
            A\bv=\bb
        </me>,
        or, explicitly, whether there are real numbers <m>x_1,x_2,\ldots,x_n</m> such that
        <me>
            \colvec{a_{11}x_1 + a_{12}x_2 +\ldots+a_{1n}x_n \\ a_{21}x_1+a_{22}x_2 +\ldots+a_{2n}x_n\\ \vdots\\ a_{m1}x_1+a_{m2}x_2+\ldots + a_{mn}x_n}=\colvec{b_1 \\ b_2 \\ \vdots \\ b_n}
        </me>.
        Put differently, whether there are solutions to the system
        <me>
            \left\{
                \begin{alignedat}{9}
                    a_{11}x_1 \ampp + \ampp a_{12}x_2 \ampp + \ampp \ldots \ampp + \ampp a_{1n}x_n \amp = \ampp b_1\\
                    a_{21}x_1 \ampp + \ampp a_{22}x_2 \ampp + \ampp \ldots \ampp + \ampp a_{2n}x_n \amp = \ampp b_2\\
                    \vdots \ampp \ampp \vdots \ampp  \ampp \ldots \ampp  \ampp \vdots \amp  \ampp \vdots\\
                    a_{m1}x_1 \ampp + \ampp a_{m2}x_2 \ampp + \ampp \ldots \ampp + \ampp a_{mn}x_n \amp = \ampp b_m
                \end{alignedat}
            \right.
        </me>
        The upshot of this discussion is that we can now look at linear systems from a different perspective. Solving a linear system is equivalent to finding a vector <m>\bv\in\R^n</m> such that
        <me>
            A\bv=\bb,
        </me>
        where <m>A</m> is the matrix formed by the coefficients <m>a_{ij}</m> of the system and <me>\bb=\colvec{b_1 \\ b_2 \\ \vdots \\ b_n}</me>.
    </p>
    <definition xml:id="def-linear-map-euclidean">
        <statement>
            <p>
                A <term>linear map</term>, or <term>linear transformation</term>, is a function <m>f:\R^n\rightarrow \R^m</m> satisfying:
                <ol>
                    <li>
                        <p>
                            <m>f(\lambda \bv)=\lambda f(\bv)</m> for every <m>\lambda\in\R</m> and <m>\bv\in\R^n</m>.
                        </p>
                    </li>
                    <li>
                        <p>
                            <m>f(\bv+\bw)=f(\bv)+f(\bw)</m> for every <m>\bv,\bw\in\R^n</m>.
                        </p>
                    </li>
                </ol>
            </p>
        </statement>
    </definition>
    <exercise>
        <p>
            Let <m>A</m> be an <m>m\times n</m> matrix and <m>B</m> an <m>n\times r</m> matrix. Verify that <m>\varphi_{AB}=\varphi_A\circ\varphi_B</m>.
        </p>
    </exercise>
    <p>
        The following important result follows immediately from the properties of matrix addition and multiplication and you should attempt to prove it before looking at the proof.
    </p>
    <proposition xml:id="prop-matrix-linear-map">
        <statement>
            <p>
                Let <m>A</m> be an <m>m\times n</m> matrix. The function <m>\varphi_A:\R^n\rightarrow \R^m</m> defined above is a linear map.
            </p>
        </statement>
        <proof>
            <p>
                We need to show that the two defining properties of a linear map hold form <m>\varphi_A</m>. In order to show this, let <m>\bv</m> and <m>\bw</m> be vectors in <m>\R^n</m> and let <m>\lambda\in\R</m> be a scalar. 
            </p>
            <p>
                By the definition of <m>\varphi_A</m>, we have <m>\varphi_A(\lambda\bv)=A(\lambda\bv)</m>. But we know that
                <me>
                    A(\lambda\bv)=\lambda(A\bv)
                </me>,
                and since <m>\varphi_A(\bv)=A\bv</m>, we conclude that <m>\varphi_A(\lambda\bv)=\lambda\varphi_A(\bv)</m>.
            </p>
            <p>
                Similarly, <m>\varphi_A(\bv+\bw)=A(\bv+\bw)=A\bv+A\bw=\varphi_A(\bv)+\varphi_A(\bw)</m>.
            </p>
        </proof>
    </proposition>
    <p>
        It is also true that every linear map <m>f:\R^n\rightarrow \R^m</m> is induced by an <m>m\times n</m> matrix, and we could even prove it here, but this section is already quite long and so I will discuss this property in a later section.
    </p>
    <p>
        There are two important numbers that are associated to a given square matrix: its <term>trace</term> and its <term>determinant</term>.
    </p>
    <definition xml:id="def-trace">
        <statement>
            <p>
                Let <m>A=(a_{ij})_{ij}</m> be an <m>n\times n</m> matrix. The <term>trace</term> of <m>A</m> is defined to be
                <me>
                    \Tr(A)=\sum_{i=1}^n a_{ii}
                </me>.
            </p>
        </statement>
    </definition>
    <p>
        In other words, the trace of a square matrix is the sum of the entries in the main diagonal.
    </p>
    <example>
        <p>
            Consider <m>A=\begin{pmatrix} 1 \amp 2 \\ -1 \amp 4\end{pmatrix}</m> and <m>B=\begin{pmatrix} -1 \amp 3 \amp 0 \\ 1 \amp 2 \amp 2 \\ -2 \amp 2 \amp -5 \end{pmatrix}</m>.
            Then
            <me>
                \Tr(A)= 1 + 4=5
            </me>
            and
            <me>
                \Tr(B) = -1 +2 -5 =-4
            </me>.
        </p>
    </example>
    <p>
        Here are some properties of the trace whose proof I will leave to you as an exercise.
    </p>
    <proposition xml:id="prop-trace-props">
        <statement>
            <p>
                The following statements hold:
                <ol>
                    <li>
                        <p>
                            If <m>A</m> and <m>B</m> are <m>n\times n</m> matrices, then <m>\Tr(A+B)=\Tr(A)+\Tr(B)</m>.
                        </p>
                    </li>
                    <li>
                        <p>
                            If <m>A</m> is a square matrix and <m>\lambda\in\R</m> is a scalar, then <m>\Tr(\lambda A)=\lambda\Tr(A)</m>.
                        </p>
                    </li>
                    <li>
                        <p>
                            If <m>A</m> is a square matrix, then <m>\Tr(A)=\Tr(A^T)</m>.
                        </p>
                    </li>
                </ol>
            </p>
        </statement>
    </proposition>
    <p>
        However, it is not true that <m>\Tr(AB)=\Tr(A)\Tr(B)</m> for every <m>m\times n</m> matrix <m>A</m> and <m>n \times m</m> matrix <m>B</m>.
    </p>
    <exercise>
        <statement>
            <p>
                Find two <m>2\times 2</m> matrices <m>A</m> and <m>B</m> such that <m>\Tr(AB)\neq \Tr(A)\Tr(B)</m>.
            </p>
        </statement>
    </exercise>
    <p>
        What we do have is the following.
    </p>
    <proposition xml:id="prop-trace-product">
        <statement>
            <p>
                Let <m>A</m> be an <m>m\times n</m> matrix, and let <m>B</m> be an <m>n\times m</m> matrix. Then <m>\Tr(AB)=\Tr(BA)</m>.
            </p>
        </statement>
        <proof>
            <p>
                Denote by <m>a_{ij}</m> the <m>(i,j)</m> entry of <m>A</m> and by <m>b_{ij}</m> that of <m>B</m>.
            </p>
            <p>
                The matrix <m>C=AB</m> is an <m>m\times m</m> matrix. If <m>c_{ij}</m> is its <m>(i,j)</m> entry, then
                <me>
                    c_{ii}=\sum_{j=1}^n a_{ij}b_{ji}
                </me>.
                This means that
                <me>
                    \Tr(AB)=\sum_{i=1}^m \sum_{j=1}^n a_{ij}b_{ji}
                </me>.
                Let's now calculate the trace of <m>D=BA</m> and compare. This matrix is an <m>n\times n</m> matrix. If we denote its <m>(i,j)</m> entry by <m>d_{ij}</m>, then
                <me>
                    d_{jj} = \sum_{i=1}^m b_{ji}a_{ij}
                </me>.
                Therefore, the trace of <m>BA</m> is given by
                <me>
                    \Tr(BA) = \sum_{j=1}^n\sum_{i=1}^m b_{ji}a_{ij}
                </me>.
                It is clear that the above expressions for <m>\Tr(AB)</m> and <m>\Tr(BA)</m> are the same.
            </p>
        </proof>
    </proposition>
    <p>
        The definition of a determinant of a square matrix is a little more involved. We will define it recursively. What this means is that I will explicitly tell you what the determinant of a <m>1\times 1</m> matrix is, but then I will simply tell you how to find the determinant of an <m>n\times n</m> matrix by calculating determinants of <m>(n-1)\times (n-1)</m> matrices.
    </p>
    <definition xml:id="def-determinant">
        <statement>
            <p>
                If <m>A=(a)</m> is a <m>1\times 1</m> matrix, the <term>determinant</term> of <m>A</m> is
                <me>\det(A)=a</me>.
            </p>
            <p>
                If <m>A=(a_{ij})_{ij}</m> is an <m>n\times n</m> matrix and we know how to calculate the determinant of <m>(n-1)\times (n-1)</m> matrices, then the <term>determinant</term> of <m>A</m> is defined to be
                <me>
                    \det(A)=\sum_{j=1}^n (-1)^{1+j}a_{1j}M_{1j}
                </me>,
                where <m>M_{1j}</m> is the determinant of the <m>(n-1)\times (n-1)</m> matrix obtained by deleting the first row and <m>j</m>th column from <m>A</m>.
            </p>
        </statement>
    </definition>
    <p>
        The determinant of a matrix <m>A</m> is sometimes denoted <m>|A|</m>.
    </p>
    <p>
        Let's work out the <m>2\times 2</m> and <m>3\times 3</m> expressions for the determinant of a general matrix.
    </p>
    <p>
        Consider a <m>2\times 2</m> matrix <m>A=\begin{pmatrix} a \amp b \\ c \amp d\end{pmatrix}</m>. We need to calculate <m>M_{11}</m> and <m>M_{12}</m>, which are determinants of <m>1\times 1</m> matrices. Recall that <m>M_{11}</m> is the determinant of the matrix obtained from <m>A</m> by deleting the first row and first column. The matrix that one obtains is <m>(d)</m>, which has determinant <m>d</m>. Thus, <m>M_{11}=d</m>. Similarly, we can easily check that <m>M_{12}=c</m>. Therefore, 
        <me>
            \det(A)=aM_{11}-bM_{12}=ad-bc
        </me>.
    </p>
    <p>
        Now that we know how to calculate the determinant of a general <m>2\times 2</m> matrix, we can piggyback off this knowledge to deduce the general expression of the determinant of
        <me>
            A=\begin{pmatrix} a \amp b \amp c \\ d \amp e \amp f \\ g \amp h \amp i \end{pmatrix}
        </me>.
        According to the definition,
        <md>
            <mrow>\det(A) \amp = a\begin{vmatrix} e \amp f \\ h \amp i \end{vmatrix} - b \begin{vmatrix} d \amp f \\ g \amp i\end{vmatrix}+c\begin{vmatrix}d \amp e \\ g \amp h\end{vmatrix}</mrow>
            <mrow> \amp = a(ei-fh) - b(di-fg) + c(dh-eg)</mrow>
            <mrow> \amp = aei + dhc + gbf - ceg - fha - ibd </mrow>
        </md>.  
    </p>
    <p>
        These two quantities will feature prominently in this course. For now, let me finish this chapter with the following important results about the determinant, which I will state without proof.
    </p>
    <p>
        Consider an <m>n\times (n-1)</m> matrix <me>A=\begin{pmatrix} a_{11} \amp a_{12} \amp \cdots \amp a_{1,n-1}\\ a_{21} \amp a_{22} \amp \cdots \amp a_{2,n-1} \\ \vdots \amp \vdots \amp \ddots \amp \vdots \\ a_{n1} \amp a_{n2} \amp \cdots \amp a_{n,n-1}\end{pmatrix}</me>. If we take a vector <m>\bv=\colvec{x_1 \\ x_2 \\ \vdots \\ x_n}</m> in <m>\R^n</m> and implant it in the matrix <m>A</m> as its <m>i</m>th column, we end up with an <m>n\times n</m> matrix 
        <me>
            A(\bv,i) = \begin{pmatrix} a_{11} \amp a_{12} \amp \cdots \amp a_{1,i-1} \amp x_1 \amp a_{1,i} \amp \cdots \amp a_{1,n-1}\\ a_{21} \amp a_{22} \amp \cdots \amp a_{2,i-1} \amp x_2 \amp a_{2,i} \amp \cdots \amp a_{2,n-1} \\ \vdots \amp \vdots \amp \ddots \amp \vdots \amp \vdots \amp \vdots \amp \ddots \amp \vdots \\ a_{n1} \amp a_{n2} \amp \cdots \amp a_{n,i-1} \amp x_n \amp a_{n,i} \amp \cdots \amp a_{n,n-1}\end{pmatrix}
        </me>
    </p>
    <example>
        <p>
            Say that <m>A=\colvec{1 \\ 2}</m> and <m>\bv = \colvec{0 \\ 5}</m>. Then
            <me>
                A(\bv,1)=\begin{pmatrix} 0 \amp 1 \\ 5 \amp 2\end{pmatrix}\qquad \text{and}\qquad A(\bv,2)=\begin{pmatrix} 1 \amp 0 \\ 2 \amp 5 \end{pmatrix}
            </me>.
        </p>
    </example>
    <p>
        So, if we fix such a matrix <m>A</m> and a integer <m>i</m> between <m>1</m> and <m>n</m>, we can construct a function <m>\delta_{A,i}: \R^n\rightarrow \R</m> by setting <m>\delta_A(\bv)=\det(A(\bv,i))</m>.
    </p>
    <proposition xml:id="prop-column-linearity">
        <statement>
            <p>
                Let <m>A</m> be an <m>n\times (n-1)</m> matrix and fix an integer <m>i\in\{1,\ldots,n\}</m>. The function <m>\delta_{A,i}</m> defined above is linear.
            </p>
        </statement>
    </proposition>
    <p>
        A more succint way of expressing <xref ref="prop-column-linearity"/> is by saying that the determinant is linear on columns.
    </p>
    <example>
        <p>
            Consider the matrices <m>A=\begin{pmatrix} 2 \amp -1 \\ 3 \amp 0\end{pmatrix}</m> and <m>B=\begin{pmatrix} -2 \amp -1 \\ 5 \amp 0\end{pmatrix}</m>. It can be easily calculated that
            <me>
                \det(A)=3\qquad \text{and}\qquad \det(B)=5
            </me>.
            Note that the matrix <m>C=\begin{pmatrix} 6 \amp -1 \\ 9 \amp 0 \end{pmatrix}</m> is obtained from <m>A</m> by multiplying the first column by <m>3</m>. Since determinants are linear on columns, we know that <m>\det(C)=3\det(A)=9</m>, which can be directly verified to be true.
        </p>
        <p>
            Similarly, note that the first column of <m>D=\begin{pmatrix} 6 \amp -1 \\ 25 \amp 0 \end{pmatrix}</m> is equal to <m>5\cdot\colvec{2 \\ 3} + 2 \cdot\colvec{-2 \\ 5}</m>. Therefore,
            <me>\det(D)=5\det(A)+2\det(B)=15+10=25</me>.
        </p>
    </example>
    <p>
        This does not mean that <m>\det(A+B)=\det(A)+\det(B)</m>. In fact, this is usually false!
    </p>
    <exercise>
        <statement>
            <p>
                Find two <m>2\times 2</m> matrices <m>A</m> and <m>B</m> such that <m>\det(A+B)\neq\det(A)+\det(B)</m>.
            </p>
        </statement>
    </exercise>
    <proposition xml:id="prop-determinant-product">
        <statement>
            <p>
                Let <m>A</m> and <m>B</m> be two <m>n\times n</m> matrices. Then <m>\det(AB)=\det(A)\cdot\det(B)</m>.
            </p>
        </statement>
    </proposition>
    <exercises xml:id="exercises-matrices">
        <exercise>
            <p>
                Evaluate the following expressions.
            </p>
            <ol marker="(a)">
                <li>
                    <p>
                        <m>\begin{pmatrix} 1 \amp -3 \amp -1 \\ 2 \amp -2 \amp -2 \end{pmatrix}\colvec{-3 \\ 5 \\ 1}</m>
                    </p>
                </li>
                <li>
                    <p>
                        <m>\begin{pmatrix}1 \amp 2 \\ -3 \amp 0 \\ -1 \amp -1 \end{pmatrix} + \begin{pmatrix} 3 \amp 0 \\ -1 \amp -5 \\ 8 \amp -2\end{pmatrix}</m>
                    </p>
                </li>
                <li>
                    <p>
                        <m>\begin{pmatrix} 3 \amp 1 \amp 1\\ 0 \amp -2 \amp 1 \end{pmatrix}\begin{pmatrix} 1 \amp 2 \amp 3 \\ 3 \amp 1 \amp -1 \\ 0 \amp 0 \amp 1\end{pmatrix}</m>
                    </p>
                </li>
                <li>
                    <p>
                        <m>\begin{pmatrix} 1 \amp 2 \\ 3 \amp 7 \end{pmatrix}\begin{pmatrix} 7 \amp -2 \\ -3 \amp 1\end{pmatrix}</m>
                    </p>
                </li>
                <li>
                    <p>
                        <m>\begin{pmatrix} 7 \amp -2 \\ -3 \amp 1\end{pmatrix}\begin{pmatrix} 1 \amp 2 \\ 3 \amp 7 \end{pmatrix}</m>
                    </p>
                </li>
                <li>
                    <p>
                        <m>\begin{pmatrix} 1 \amp 2 \amp 4 \\ -2 \amp 1 \amp 0 \\ -2 \amp 1 \amp 1\end{pmatrix}\left(2\begin{pmatrix} 3 \amp 2 \\ 0 \amp 1 \\ -1 \amp -1 \end{pmatrix} + 3\begin{pmatrix} 1 \amp 1 \\ 1 \amp 1 \\ 1 \amp 1 \end{pmatrix}\right)</m>
                    </p>
                </li>
            </ol>
        </exercise>
        <exercise>
            <p>
                Evaluate <m>p(A)</m> for each polynomial <m>p(X)\in\R[X]</m> and square matrix <m>A</m> given.
            </p>
            <ol marker="(a)">
                <li>
                    <p>
                        <m>A=\begin{pmatrix} 1 \amp 3 \\ 2 \amp 5\end{pmatrix},\quad p(X)=X^2-6X-1</m>
                    </p>
                </li>
                <li>
                    <p>
                        <m>A=\begin{pmatrix} -2 \amp 0 \\ -1 \amp 1\end{pmatrix},\quad p(X)=X^3-2X^2+X-1</m>
                    </p>
                </li>
                <li>
                    <p>
                        <m>A=\begin{pmatrix} 1 \amp 2 \amp -1 \\ 0 \amp -3 \amp -1 \\ 1 \amp 0 \amp -1 \end{pmatrix},\quad p(X)=2X^2+X-2</m>
                    </p>
                </li>
            </ol>
        </exercise>
        <exercise>
            <statement>
                <p>
                    If a square matrix <m>A</m> satisfies <m>A^2=A</m>, we say that <m>A</m> is <term>idempotent</term>. For example, the <m>n\times n</m> identity matrix is idempotent for every <m>n\geq 1</m>. Give an example of an idempotent matrix that is not an identity matrix.
                </p>
            </statement>
        </exercise>
        <exercise>
            <statement>
                <p>
                    If a square matrix <m>A</m> satisfies <m>A^k=0</m> for some integer <m>k\geq 1</m>, we say that <m>A</m> is <term>nilpotent</term>. For example, the zero matrix is nilpotent. Give an example of a non-zero nilpotent matrix.
                </p>
            </statement>
            <hint>
                <p>
                    There are examples of <m>2\times 2</m> non-zero matrices that satisfy <m>A^2=0</m>.
                </p>
            </hint>
        </exercise>
        <exercise>
            <p>
                Let <m>A</m> be an <m>m\times n</m> matrix. Denoting by <m>\be_i</m> the <m>i</m>th standard unit vector (<m>1\leq i\leq n</m>), show that <m>A\be_i</m> is the <m>i</m>th column of <m>A</m>.
            </p>
            <p>
                This means that the image of <m>\be_i</m> under the linear map <m>\varphi_A</m> is the vector represented by the <m>i</m>th column of <m>A</m>.
            </p>
        </exercise>
        <exercise>
            <p>
                Consider the matrix <m>A=\begin{pmatrix} 1 \amp 3 \\ 5 \amp -1\end{pmatrix}</m>. Find a vector <m>\bv\in\R^2</m> such that <m>\varphi_A(\bv)=\colvec{-2 \\ 1}</m>.
            </p>
        </exercise>
        <exercise>
            <statement>
                <p>
                    For each matrix <m>A</m> below, find a vector <m>\bx</m> that satisfies <m>A\bx=\bz</m>, or explain why such a vector does not exist.
                    <ol marker="(a)">
                        <li>
                            <p>
                                <m>A=\begin{pmatrix}1 \amp 2 \\ -1 \amp 1\end{pmatrix}</m>
                            </p>
                        </li>
                        <li>
                            <p>
                                <m>A=\begin{pmatrix} -1 \amp 2 \amp 0 \\ 1 \amp 1 \amp 1 \end{pmatrix}</m>
                            </p>
                        </li>
                        <li>
                            <p>
                                <m>A=\begin{pmatrix} 1 \amp 2 \\ -1 \amp 0 \\ 2 \amp 2\end{pmatrix}</m>
                            </p>
                        </li>
                    </ol>
                </p>
            </statement>
        </exercise>
        <exercise>
            <p>
                The following is a list of linear maps. For each one for them, find a matrix that induces it.
            </p>
            <ol marker="(a)">
                <li>
                    <p>
                        <m>f:\R^2\rightarrow \R^3,\quad (x,y)\mapsto (2x, x-y,3x+y)</m>
                    </p>
                </li>
                <li>
                    <p>
                        <m>g:\R^2\rightarrow \R^2,\quad (x,y)\mapsto \left(\frac{\sqrt{3}}{2}x-\frac{1}{2}y,\frac{1}{2}x+\frac{\sqrt{3}}{2}y\right)</m>
                    </p>
                </li>
                <li>
                    <p>
                        <m>h:\R^2\rightarrow \R^2,\quad (x,y)\mapsto (2x,y)</m>
                    </p>
                </li>
                <li>
                    <p>
                        <m>k:\R^3\rightarrow \R^3,\quad \left(x, \frac{\sqrt{3}}{2}y-\frac{1}{2}z,\frac{1}{2}y+\frac{\sqrt{3}}{2}z\right)</m>
                    </p>
                </li>
            </ol>
        </exercise>
        <exercise>
            <p>
                Recall that the <m>n\times n</m> identity matrix <m>\Id_n</m> is the diagonal matrix whose entries in the main diagonal are all <m>1</m>. Verify that <m>\varphi_{\Id_n}:\R^n\rightarrow\R^n</m> is the identity map.
            </p>
        </exercise>
        <exercise>
            <p>
                Show that if <m>f,g:\R^n\rightarrow \R^m</m> are linear maps and <m>a,b\in\R</m>, then <m>af+bg</m> is a linear map.
            </p>
        </exercise>
        <exercise>
            <p>
                Show that if <m>f:\R^n\rightarrow \R^m</m> and <m>g:\R^m\rightarrow \R^s</m> are linear maps, then the composition <m>g\circ f</m> is a linear map too.
            </p>
        </exercise>
        <exercise>
            <statement>
                <p>
                    Calculate the trace and determinant of each of the following matrices.
                    <ol>
                        <li>
                            <p>
                                <m>\begin{pmatrix} -2 \amp 2 \\ 3 \amp 1\end{pmatrix}</m>
                            </p>
                        </li>
                        <li>
                            <p>
                                <m>\begin{pmatrix} 0 \amp -1 \\ -1 \amp 0 \end{pmatrix}</m>
                            </p>
                        </li>
                        <li>
                            <p>
                                <m>\begin{pmatrix} 1 \amp 2 \\ 2 \amp 4\end{pmatrix}</m>
                            </p>
                        </li>
                        <li>
                            <p>
                                <m>\begin{pmatrix} 2 \amp 0 \amp 0 \\ 0 \amp 3 \amp 0 \\ 0 \amp 0 \amp -1\end{pmatrix}</m>
                            </p>
                        </li>
                        <li>
                            <p>
                                <m>\begin{pmatrix} -1 \amp 2 \amp 1 \\ 2 \amp 3 \amp 0 \\ 3 \amp -1 \amp 0\end{pmatrix}</m>
                            </p>
                        </li>
                        <li>
                            <p>
                                <m>\begin{pmatrix} 2 \amp 2 \amp 1 \\ -1 \amp -1 \amp 4 \\ 3 \amp 3 \amp 7\end{pmatrix}</m>
                            </p>
                        </li>
                    </ol>
                </p>
            </statement>
        </exercise>
        <exercise>
            <p>
                Show that <m>\det(\diag(\lambda_1,\lambda_2,\ldots,\lambda_n))=\lambda_1\cdot\lambda_2\cdot\ldots\cdot\lambda_n</m> and <m>\Tr(\diag(\lambda_1,\lambda_2,\ldots,\lambda_n)) = \lambda_1+\lambda_2+\cdots+\lambda_n</m>.
            </p>
        </exercise>
        <exercise>
            <p>
                Show that <m>\det(\Id_n)=1</m> and <m>\Tr(\Id_n)=n</m> for every integer <m>n\geq 1</m>.
            </p>
        </exercise>
        <exercise>
            <p>
                &#9733; Show that <m>\det(A)=\det(A^T)</m>.
            </p>
        </exercise>
        <exercise>
            <p>
                &#9733; Use the fact that the determinant is linear on columns to show that if <m>A</m> is an <m>n\times n</m> matrix, then <m>\det(\lambda A)=\lambda^n\det(A)</m> for every <m>\lambda\in\R</m>.
            </p>
        </exercise>
        <exercise>
            <statement>
                <p>
                    &#9733; Show that if <m>A</m> is a square matrix with two equal columns, then <m>\det(A)=0</m>.
                </p>
            </statement>
        </exercise>
        <exercise>
            <p>
                &#9733; Show that if <m>f:\R^n\rightarrow \R^n</m> is a bijective linear map, then its inverse <m>f^{-1}</m> is a linear map as well.
            </p>
        </exercise>
    </exercises>
</section>